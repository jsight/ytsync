{"id":"ytsync-3c5","title":"Transcript Extraction","description":"Research and implement transcript extraction from YouTube videos. Support auto-generated captions and manually uploaded transcripts.","status":"open","priority":2,"issue_type":"epic","created_at":"2026-01-10T16:27:14.170346-05:00","updated_at":"2026-01-10T16:27:14.170346-05:00","labels":["feature"]}
{"id":"ytsync-3c5.1","title":"Spike: Transcript API Research","description":"Research transcript extraction approaches:\n- YouTube's timedtext API endpoints\n- yt-dlp transcript extraction patterns\n- Caption formats (srv1, srv2, srv3, json3, ttml, vtt)\n- Auto-generated vs manual caption detection\n- Language selection and availability checking","notes":"RESEARCH FINDINGS: Transcript Extraction Approaches\n\n## 1. YOUTUBE TIMEDTEXT API ENDPOINTS\n- Primary: /api/timedtext endpoint (used by web player)\n- Format: Accessible via: www.youtube.com/api/timedtext?v={VIDEO_ID}\u0026lang={LANG_CODE}\n- Returns: ttml/xml format with timed text\n- No official public API - reverse-engineered from web player behavior\n- Advantages: Direct API access, no video download needed\n- Limitations: Subject to rate limiting, YouTube may change endpoints\n\n## 2. YT-DLP TRANSCRIPT EXTRACTION\n- --write-subs: Downloads available manual/user-uploaded subtitles\n- --write-auto-subs: Downloads auto-generated captions from YouTube\n- --sub-langs: Specify language(s) to download\n- --skip-download: Extract captions WITHOUT downloading video file (key advantage)\n- Default output formats: vtt, ttml, or json3\n- More reliable than direct API calls (abstraction layer handles changes)\n- Active maintenance and community support\n\n## 3. CAPTION FORMATS SUPPORTED\n- srv1: Legacy YouTube subtitle format (XML-based)\n- srv2: Alternative XML format variant\n- srv3: Compressed XML format\n- json3: Modern JSON format (most machine-readable)\n- ttml: TTML (Timed Text Markup Language) - W3C standard\n- vtt: WebVTT format - human readable, common on web\n- Best for parsing: json3 (structured) or vtt (simple)\n- Best for archival: ttml (standard format)\n\n## 4. AUTO-GENERATED VS MANUAL CAPTION DETECTION\n- Metadata available in caption lists returned from video info\n- Manual captions: Listed with 'kind': 'standard' (have higher accuracy)\n- Auto-generated: Listed with kind: 'asr' (speech-to-text, may have errors)\n- Availability varies by video and language\n- Some videos have BOTH manual and auto-generated captions\n- Strategy: Prefer manual when available, fall back to auto-generated\n\n## 5. LANGUAGE SELECTION \u0026 AVAILABILITY\n- Requires fetching video info first to get available languages\n- YouTube player stores available languages in initial data JSON\n- Auto-generated captions available in wider range of languages than manual\n- Can specify default language or preference list\n- Fallback chain: preferred lang → english → any available\n- yt-dlp supports: --sub-langs [lang_code] or --all-subs for all\n\n## 6. GETTING TRANSCRIPTS WITHOUT VIDEO DOWNLOAD\nRecommended approach: yt-dlp with --skip-download flag\n- Command: yt-dlp --skip-download --write-auto-subs --write-subs {VIDEO_URL}\n- Extracts ONLY subtitle/caption data\n- Minimal bandwidth usage\n- Fast execution (seconds vs minutes)\n- Alternative: Direct timedtext API + video info API (more complex)\n- Direct API advantage: No dependency on external tool\n- Direct API disadvantage: More maintenance when YouTube changes\n\n## RECOMMENDED IMPLEMENTATION STRATEGY\n1. Primary: Use yt-dlp as subprocess (proven, maintained)\n2. Fallback: Direct timedtext API for cases where yt-dlp unavailable\n3. Language priority: Manual \u003e Auto-generated, configurable preference\n4. Output format: json3 for processing, vtt for display/archival\n5. Error handling: Graceful degradation, language fallback\n6. Caching: Store transcript info (available langs, formats)\n7. Architecture: Separate transcript fetcher module, pluggable backends","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T16:27:26.094179-05:00","updated_at":"2026-01-10T16:40:41.898172-05:00","closed_at":"2026-01-10T16:40:41.898174-05:00","labels":["research","spike"],"dependencies":[{"issue_id":"ytsync-3c5.1","depends_on_id":"ytsync-3c5","type":"parent-child","created_at":"2026-01-10T16:27:26.096581-05:00","created_by":"daemon"}]}
{"id":"ytsync-3c5.10","title":"Test: Transcript Extraction Edge Cases \u0026 Error Handling","description":"Test videos with no captions, age-restricted videos, live streams, deleted videos. Test rate limiting handling. Test network failures and timeouts. Verify graceful error messages and recovery.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T16:40:39.39672-05:00","updated_at":"2026-01-10T16:40:39.39672-05:00","labels":["implementation","testing"],"dependencies":[{"issue_id":"ytsync-3c5.10","depends_on_id":"ytsync-3c5","type":"parent-child","created_at":"2026-01-10T16:40:39.397213-05:00","created_by":"daemon"}]}
{"id":"ytsync-3c5.11","title":"Test: Transcript Extraction Performance \u0026 Caching","description":"Test extraction speed without video download. Verify caching of language availability data. Test batch transcript extraction. Validate memory usage with large transcript files.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T16:40:39.787568-05:00","updated_at":"2026-01-10T16:40:39.787568-05:00","labels":["implementation","testing"],"dependencies":[{"issue_id":"ytsync-3c5.11","depends_on_id":"ytsync-3c5","type":"parent-child","created_at":"2026-01-10T16:40:39.788079-05:00","created_by":"daemon"}]}
{"id":"ytsync-3c5.2","title":"Spike: Transcript Parsing and Cleaning","description":"Research transcript post-processing:\n- Removing timing information for plain text\n- Handling auto-generated caption artifacts (filler words, repetitions)\n- Paragraph/sentence segmentation\n- Speaker identification (if available)","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-10T16:27:26.491122-05:00","updated_at":"2026-01-10T16:51:14.776692-05:00","closed_at":"2026-01-10T16:51:14.776695-05:00","labels":["research","spike"],"dependencies":[{"issue_id":"ytsync-3c5.2","depends_on_id":"ytsync-3c5","type":"parent-child","created_at":"2026-01-10T16:27:26.491676-05:00","created_by":"daemon"}]}
{"id":"ytsync-3c5.3","title":"Implement yt-dlp Transcript Extractor Module","description":"Create transcript extractor using yt-dlp subprocess integration. Support manual and auto-generated captions, language selection, and --skip-download mode. Output formats: json3 for processing, vtt for display.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T16:40:31.210239-05:00","updated_at":"2026-01-10T19:20:45.989074-05:00","closed_at":"2026-01-10T19:20:45.989074-05:00","close_reason":"Closed","labels":["implementation"],"dependencies":[{"issue_id":"ytsync-3c5.3","depends_on_id":"ytsync-3c5","type":"parent-child","created_at":"2026-01-10T16:40:31.212495-05:00","created_by":"daemon"}]}
{"id":"ytsync-3c5.4","title":"Implement Direct YouTube timedtext API Fallback","description":"Implement direct timedtext API integration as fallback when yt-dlp unavailable. Query /api/timedtext endpoint directly. Handle rate limiting and YouTube endpoint changes gracefully.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T16:40:31.597947-05:00","updated_at":"2026-01-10T16:40:31.597947-05:00","labels":["implementation"],"dependencies":[{"issue_id":"ytsync-3c5.4","depends_on_id":"ytsync-3c5","type":"parent-child","created_at":"2026-01-10T16:40:31.598508-05:00","created_by":"daemon"}]}
{"id":"ytsync-3c5.5","title":"Implement Transcript Format Conversion Pipeline","description":"Create converters between caption formats: json3, vtt, ttml, srv1/2/3. Standardize on internal representation. Support both input parsing and output formatting.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T16:40:32.223967-05:00","updated_at":"2026-01-10T16:40:32.223967-05:00","labels":["implementation"],"dependencies":[{"issue_id":"ytsync-3c5.5","depends_on_id":"ytsync-3c5","type":"parent-child","created_at":"2026-01-10T16:40:32.224501-05:00","created_by":"daemon"}]}
{"id":"ytsync-3c5.6","title":"Implement Language Availability \u0026 Preference System","description":"Fetch available caption languages from video info. Implement preference chain: manual \u003e auto-generated. Support user language preferences with fallback to English. Cache language availability data.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T16:40:32.642292-05:00","updated_at":"2026-01-10T16:40:32.642292-05:00","labels":["implementation"],"dependencies":[{"issue_id":"ytsync-3c5.6","depends_on_id":"ytsync-3c5","type":"parent-child","created_at":"2026-01-10T16:40:32.64299-05:00","created_by":"daemon"}]}
{"id":"ytsync-3c5.7","title":"Test: Transcript Extraction with Multiple Languages","description":"Test transcript extraction across videos with multiple available languages. Verify manual caption priority over auto-generated. Test language fallback behavior. Validate language availability detection.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T16:40:38.195403-05:00","updated_at":"2026-01-10T16:40:38.195403-05:00","labels":["implementation","testing"],"dependencies":[{"issue_id":"ytsync-3c5.7","depends_on_id":"ytsync-3c5","type":"parent-child","created_at":"2026-01-10T16:40:38.197995-05:00","created_by":"daemon"}]}
{"id":"ytsync-3c5.8","title":"Test: Caption Format Conversion Accuracy","description":"Test conversion accuracy between all caption formats (json3, vtt, ttml, srv1/2/3). Verify timing data preservation. Validate special character handling. Test round-trip conversions.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T16:40:38.613554-05:00","updated_at":"2026-01-10T16:40:38.613554-05:00","labels":["implementation","testing"],"dependencies":[{"issue_id":"ytsync-3c5.8","depends_on_id":"ytsync-3c5","type":"parent-child","created_at":"2026-01-10T16:40:38.614084-05:00","created_by":"daemon"}]}
{"id":"ytsync-3c5.9","title":"Test: yt-dlp vs Direct API Transcript Extraction","description":"Compare yt-dlp and direct timedtext API outputs. Verify consistency and completeness. Test fallback behavior when yt-dlp unavailable. Benchmark performance and bandwidth usage.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T16:40:39.010865-05:00","updated_at":"2026-01-10T16:40:39.010865-05:00","labels":["implementation","testing"],"dependencies":[{"issue_id":"ytsync-3c5.9","depends_on_id":"ytsync-3c5","type":"parent-child","created_at":"2026-01-10T16:40:39.011375-05:00","created_by":"daemon"}]}
{"id":"ytsync-ad3","title":"HTTP Client Infrastructure","description":"Build robust HTTP client infrastructure for YouTube interactions including rate limiting, retries, and error handling.","status":"open","priority":2,"issue_type":"epic","created_at":"2026-01-10T16:27:14.552191-05:00","updated_at":"2026-01-10T16:27:14.552191-05:00","labels":["infrastructure"]}
{"id":"ytsync-ad3.1","title":"Spike: Rate Limiting and Backoff Strategies","description":"Research HTTP client resilience patterns:\n- YouTube rate limit detection and response codes\n- Exponential backoff with jitter\n- Request queuing and throttling\n- Concurrent request limits\n- Session/cookie management","notes":"# HTTP Client Resilience Patterns for YouTube - Research Findings\n\n## Executive Summary\n\nThis spike documents HTTP client resilience patterns essential for building a robust YouTube interaction layer. The research covers rate limiting detection, exponential backoff strategies, concurrent request management, session persistence, and circuit breaker patterns.\n\n---\n\n## 1. YouTube Rate Limit Detection\n\n### HTTP Status Codes\n\nYouTube uses standard HTTP status codes to signal rate limiting and errors:\n\n- **429 Too Many Requests**: Primary rate limit indicator\n  - Indicates client has exceeded rate limit quota\n  - Always includes `Retry-After` header\n  - Most reliable rate limit signal\n  \n- **403 Forbidden**: Access denied (rate limiting or policy violation)\n  - May indicate IP-based rate limiting\n  - Can also indicate channel access restrictions\n  - Should be treated as backoff trigger\n  \n- **503 Service Unavailable**: Temporary server unavailability\n  - May include `Retry-After` header\n  - Safe to retry with backoff\n  \n- **500, 502, 504**: Transient server errors\n  - 500: Internal Server Error (temporary)\n  - 502: Bad Gateway (transient)\n  - 504: Gateway Timeout (transient)\n  - All safe to retry with backoff\n\n- **404, 410**: Permanent not found\n  - Do NOT retry\n  - Indicates missing resource\n\n### Response Headers\n\nParse these headers for rate limit information:\n\n- `Retry-After`: Contains seconds (integer) or HTTP date\n  - Example: `Retry-After: 120` (seconds)\n  - Example: `Retry-After: Fri, 01 Jan 2026 00:00:00 GMT` (HTTP date)\n  - Always respect when present\n  \n- `X-RateLimit-Remaining`: Requests remaining in quota (if provided)\n  - Helps predict when rate limit will be hit\n  \n- `X-RateLimit-Reset`: Unix timestamp of quota reset\n  - Allows precise calculation of wait time\n  \n- `X-RateLimit-Limit`: Total quota for window\n  - Helps understand quota size\n\n### YouTube-Specific Patterns\n\nFrom research of yt-dlp and YouTube interactions:\n\n- **Innertube API**: Returns 429 after roughly 20-30 requests/minute from single IP\n- **Data API**: Hard quota of 10,000 units/day per project API key\n- **IP-based blocking**: Sustained high request rates trigger temporary IP bans\n  - Block duration: 5-30 minutes depending on severity\n  - Affects all requests from IP, all endpoints\n- **CAPTCHA challenges**: Excessive requests may return 403 with challenge HTML\n- **User-Agent detection**: Suspicious or missing User-Agent triggers rate limiting\n- **Fingerprinting**: YouTube uses behavioral analysis beyond just IP/request rate\n\n### Detection Strategy\n\n1. Immediately check HTTP status code\n2. For 429/503: Check `Retry-After` header for delay\n3. For 403: Treat as rate limit if no other context (conservative approach)\n4. For 50x errors: Use exponential backoff\n5. Log all rate limit incidents with context for debugging\n\n---\n\n## 2. Exponential Backoff with Jitter Implementation\n\n### Algorithm\n\nThe classic exponential backoff with jitter formula:\n\n```\nattempt = 0 to max_attempts\nbase_delay = initial_delay * (multiplier ^ attempt)\ncapped_delay = min(base_delay, max_delay)\njitter_factor = 0.5 + random(0, 1)  // Range: 0.5 to 1.5\nfinal_delay = capped_delay * jitter_factor\nsleep(final_delay)\n```\n\n### Recommended Configuration\n\n- **initial_delay**: 1 second (YouTube rarely needs less)\n- **multiplier**: 2.0 (doubles each attempt)\n- **max_delay**: 30-60 seconds (don't wait forever)\n- **jitter**: +/- 20-30% variation\n  - Formula: `delay * (0.8 + random(0, 0.4))` for +/-20%\n  - Formula: `delay * (0.7 + random(0, 0.6))` for +/-30%\n- **max_attempts**: \n  - 5 for transient errors (5xx, timeout, 429)\n  - 0 for permanent errors (4xx except 429/403)\n  - 0 for 404, 410 (not found)\n\n### Backoff Sequence Example\n\nWith initial=1s, multiplier=2.0, max=30s, jitter=+/-20%:\n\n| Attempt | Base Delay | Capped | With Jitter (±20%) | Actual (example) |\n|---------|-----------|--------|-------------------|------------------|\n| 1       | 1s        | 1s     | 0.8-1.2s          | 0.9s            |\n| 2       | 2s        | 2s     | 1.6-2.4s          | 2.1s            |\n| 3       | 4s        | 4s     | 3.2-4.8s          | 3.8s            |\n| 4       | 8s        | 8s     | 6.4-9.6s          | 7.5s            |\n| 5       | 16s       | 16s    | 12.8-19.2s        | 15.2s           |\n| 6       | 32s       | 30s    | 24-36s → 24-30s   | 27.8s           |\n\nTotal delay across 6 attempts: ~57 seconds maximum\n\n### Why Jitter is Critical\n\n**Without jitter (synchronized retries):**\n- All clients wait identical times\n- All clients retry simultaneously at T=1s, T=3s, T=7s, etc.\n- Creates thundering herd problem\n- Server gets massive spike of requests\n- Can trigger cascading failures\n\n**With jitter:**\n- Clients retry at slightly different times\n- Spreads retry traffic uniformly across time\n- Server load increases gradually\n- Reduces chance of cascade\n- Standard practice in cloud systems\n\n### Implementation Notes\n\n- Use crypto/rand for jitter, not math/rand (more secure, better distribution)\n- Round jitter to millisecond precision (not nanoseconds)\n- Log each retry attempt with delay for debugging\n- Respect `Retry-After` header when present (may override backoff)\n- Consider per-endpoint backoff (different services need different strategies)\n\n---\n\n## 3. Request Queuing and Throttling Strategies\n\n### Token Bucket Rate Limiter\n\nThe token bucket algorithm is simplest and most effective for YouTube:\n\n**How it works:**\n1. Bucket starts with `capacity` tokens\n2. Tokens regenerate at `rate` tokens/second\n3. Each request costs 1 token\n4. If tokens available: deduct and allow request\n5. If no tokens: wait until token available\n\n**Example:**\n- Capacity: 3 tokens\n- Rate: 2 tokens/second\n- Allows bursts: up to 3 requests immediately\n- Then sustains: 2 requests/second steady state\n\n**Implementation with golang.org/x/time/rate:**\n\n```go\nimport \"golang.org/x/time/rate\"\n\nlimiter := rate.NewLimiter(rate.Limit(2), 3)  // 2 req/s, capacity 3\n\n// For each request:\nif !limiter.Allow() {\n  // Rate limited, must wait\n  ctx, cancel := context.WithTimeout(ctx, 1*time.Second)\n  err := limiter.Wait(ctx)\n  if err != nil {\n    return fmt.Errorf(\"rate limit timeout: %w\", err)\n  }\n}\n```\n\n### Per-Endpoint Configuration\n\nYouTube has different rate limits per endpoint:\n\n1. **Innertube API** (`/youtubei/v1/browse`, etc.)\n   - Safe rate: 2-3 requests/second\n   - Burst capacity: 5 requests\n   - Used for: channel video lists, search, recommendations\n   \n2. **RSS Feeds** (`/feeds/videos.xml`)\n   - Rate: No effective limit\n   - Burst: No limit\n   - However: Only returns 15 most recent videos\n   \n3. **YouTube Data API v3**\n   - Rate: Quota-based (10,000 units/day)\n   - Per-second limit: ~1-2 requests/second per project\n   - Burst: Limited\n   \n4. **Other endpoints** (thumbnails, etc.)\n   - Rate: 5-10 requests/second per IP\n   - May vary by resource type\n\n### Sliding Window Alternative\n\nFor stricter control, sliding window approach:\n- Track request timestamps in window\n- Reject if count exceeds limit in window\n- More complex but stricter enforcement\n- Recommended only if token bucket insufficient\n\n**When to use:**\n- Very strict rate limit enforcement needed\n- Token bucket allows too much burstiness\n- Quota must be evenly distributed\n\n### Implementation Strategy\n\n- Create rate limiter per endpoint/host\n- Configure via YAML/environment\n- Allow override for testing\n- Log when rate limit applied (important metric)\n\n---\n\n## 4. Concurrent Request Limits for YouTube\n\n### HTTP Transport Configuration\n\nGo's `http.Client` uses a transport with default pooling:\n\n```go\ntransport := \u0026http.Transport{\n  MaxIdleConns:        20,           // Total idle connections\n  MaxIdleConnsPerHost: 5,            // Idle per host (YouTube domain)\n  MaxConnsPerHost:     10,           // Total concurrent per host\n  IdleConnTimeout:     90 * time.Second,\n  DialTimeout:         30 * time.Second,\n  ReadTimeout:         30 * time.Second,\n}\n\nclient := \u0026http.Client{\n  Transport: transport,\n  Timeout:   60 * time.Second,  // Total request timeout\n}\n```\n\n### Recommended Settings for YouTube\n\n| Setting | Value | Rationale |\n|---------|-------|-----------|\n| MaxConnsPerHost | 10 | YouTube safe limit |\n| MaxIdleConnsPerHost | 5 | Keep some idle for reuse |\n| MaxIdleConns | 20 | Across all hosts |\n| IdleConnTimeout | 90s | YouTube keeps connections 2-3 min |\n| DialTimeout | 30s | DNS + TCP handshake |\n| ReadTimeout | 30s | Full response transfer |\n| Total Timeout | 60s | Safety net |\n\n### HTTP/2 Considerations\n\nGo's http.Client automatically uses HTTP/2 if available:\n- HTTP/2 supports multiplexing (multiple streams on one connection)\n- Allows more concurrent requests without connection overhead\n- YouTube supports HTTP/2 on all endpoints\n- Go handles protocol negotiation automatically via TLS ALPN\n\n### Connection Reuse\n\nKeep-alive connections are essential:\n- Default HTTP/1.1 behavior supports keep-alive\n- Reusing connections reduces latency\n- Reduces TCP handshake overhead\n- YouTube honors keep-alive and connection pooling\n\n### DOS Protection Considerations\n\nBe careful not to appear like DOS attack:\n- Spread concurrent requests (don't spike)\n- Respect rate limits\n- Use realistic User-Agent\n- Maintain session consistency (cookies)\n- Vary request patterns slightly\n\n---\n\n## 5. Session and Cookie Management\n\n### Cookie Jar Setup\n\nGo provides built-in cookie jar via `net/http/cookiejar`:\n\n```go\nimport (\n  \"net/http/cookiejar\"\n  \"golang.org/x/net/publicsuffix\"\n)\n\njar, err := cookiejar.New(\u0026cookiejar.Options{\n  PublicSuffixList: publicsuffix.List,\n})\n\nclient := \u0026http.Client{\n  Jar: jar,\n}\n```\n\n### Persistent Cookie Storage\n\nFor session state across application restarts:\n\n```go\n// Save cookies to file\nfunc saveCookies(jar http.CookieJar, path string) error {\n  u, _ := url.Parse(\"https://www.youtube.com\")\n  cookies := jar.Cookies(u)\n  data := json.Marshal(cookies)\n  return os.WriteFile(path, data, 0600)\n}\n\n// Load cookies from file\nfunc loadCookies(jar http.CookieJar, path string) error {\n  data, _ := os.ReadFile(path)\n  var cookies []*http.Cookie\n  json.Unmarshal(data, \u0026cookies)\n  u, _ := url.Parse(\"https://www.youtube.com\")\n  jar.SetCookies(u, cookies)\n  return nil\n}\n```\n\n### User-Agent Management\n\nYouTube actively blocks requests with suspicious User-Agent:\n\n**Realistic User-Agents to use:**\n- Chrome: `Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36`\n- Firefox: `Mozilla/5.0 (X11; Linux x86_64; rv:121.0) Gecko/20100101 Firefox/121.0`\n- Safari: `Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1.2 Safari/605.1.15`\n\n**Bad User-Agents (will be rate limited):**\n- `Go-http-client/1.1` (Go default)\n- `Python-Requests/...\" (yt-dlp default)\n- Empty or missing User-Agent\n- Overly generic agents\n\n**Rotation strategy:**\n- Change User-Agent periodically (every 100-1000 requests)\n- Switch between Chrome, Firefox, Safari randomly\n- Don't use same agent for every request (improves stealth)\n\n### Request Headers Strategy\n\nSet headers to mimic real browser:\n\n```go\nreq.Header.Set(\"User-Agent\", userAgent)\nreq.Header.Set(\"Accept\", \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\")\nreq.Header.Set(\"Accept-Language\", \"en-US,en;q=0.5\")\nreq.Header.Set(\"Accept-Encoding\", \"gzip, deflate\")\nreq.Header.Set(\"Connection\", \"keep-alive\")\nreq.Header.Set(\"Upgrade-Insecure-Requests\", \"1\")\nreq.Header.Set(\"Sec-Fetch-Dest\", \"document\")\nreq.Header.Set(\"Sec-Fetch-Mode\", \"navigate\")\nreq.Header.Set(\"Sec-Fetch-Site\", \"none\")\n```\n\n### Innertube API Specifics\n\nFor innertube API requests, additional headers:\n\n```go\nreq.Header.Set(\"X-YouTube-Client-Name\", \"1\")  // Web client\nreq.Header.Set(\"X-YouTube-Client-Version\", \"2.0\")  // Approximate version\nreq.Header.Set(\"Content-Type\", \"application/json\")\nreq.Header.Set(\"Origin\", \"https://www.youtube.com\")\nreq.Header.Set(\"Referer\", \"https://www.youtube.com/\")\n```\n\n### Security Considerations\n\n- Store cookies in file with restricted permissions (0600)\n- Don't log full cookies (may contain sensitive data)\n- Rotate User-Agent to avoid fingerprinting\n- Clear cookies periodically if getting blocked\n- Consider headless browser fallback if direct API fails\n\n---\n\n## 6. Circuit Breaker Pattern\n\n### Three States\n\nA circuit breaker has three distinct states:\n\n**1. CLOSED (Normal operation)**\n- Requests pass through to the service\n- Failures are tracked\n- Transitions to OPEN if failure threshold exceeded\n- Typical threshold: 5 consecutive failures\n\n**2. OPEN (Service is down, fail fast)**\n- Requests fail immediately without calling service\n- No service calls are attempted\n- After timeout, transitions to HALF_OPEN to test recovery\n- Typical timeout: 30-60 seconds\n\n**3. HALF_OPEN (Testing recovery)**\n- Single test request allowed through\n- If successful: transition to CLOSED, reset counters\n- If fails: transition back to OPEN, restart timeout\n- Limits damage from failed recovery attempts\n\n### State Diagram\n\n```\nCLOSED\n  |\n  | (5 consecutive failures)\n  v\nOPEN\n  |\n  | (30-60 second timeout)\n  v\nHALF_OPEN\n  |\n  +---\u003e (success) ----\u003e CLOSED\n  |\n  +---\u003e (failure) ----\u003e OPEN\n```\n\n### Distinguishing Error Types\n\nNot all errors warrant circuit breaking:\n\n**Permanent errors (no circuit break):**\n- 404 Not Found\n- 410 Gone\n- 403 Forbidden (invalid auth)\n- These indicate client error, won't resolve with retry\n\n**Transient errors (trigger circuit break):**\n- 429 Too Many Requests\n- 503 Service Unavailable\n- 500 Internal Server Error\n- Network timeouts\n- Connection refused\n- DNS resolution failures\n\n**Categorization logic:**\n```go\nif statusCode \u003e= 400 \u0026\u0026 statusCode \u003c 500 \u0026\u0026 statusCode != 429 \u0026\u0026 statusCode != 403 {\n  return permanent error  // Don't retry\n}\nreturn transient error  // Retry with backoff\n```\n\n### Implementation for YouTube\n\nCreate circuit breaker per endpoint:\n\n```go\ntype CircuitBreaker struct {\n  endpoint      string\n  state         string  // \"closed\", \"open\", \"half-open\"\n  failures      int\n  lastFailTime  time.Time\n  mu            sync.RWMutex\n}\n\n// Configuration\nconst (\n  FailureThreshold = 5\n  OpenTimeout      = 30 * time.Second\n)\n\nfunc (cb *CircuitBreaker) Call(fn func() error) error {\n  cb.mu.Lock()\n  defer cb.mu.Unlock()\n  \n  if cb.state == \"open\" {\n    if time.Since(cb.lastFailTime) \u003e OpenTimeout {\n      cb.state = \"half-open\"\n      cb.failures = 0\n    } else {\n      return fmt.Errorf(\"circuit breaker open for %s\", cb.endpoint)\n    }\n  }\n  \n  err := fn()\n  \n  if err != nil {\n    cb.failures++\n    cb.lastFailTime = time.Now()\n    \n    if cb.failures \u003e= FailureThreshold {\n      cb.state = \"open\"\n    }\n    return err\n  }\n  \n  // Success\n  cb.state = \"closed\"\n  cb.failures = 0\n  return nil\n}\n```\n\n### Monitoring and Logging\n\nCircuit breaker state is important operational metric:\n\n- Log every state transition with timestamp\n- Count failures by endpoint\n- Track half-open recovery success rate\n- Alert if circuit open for extended period\n- Metrics: failure rate, average response time, state duration\n\n### Per-Endpoint vs Global\n\nRecommendation:\n- Per-endpoint circuit breakers (separate for innertube, RSS, data API)\n- Allows single endpoint failure without affecting others\n- Enables granular fallback strategies\n- Example: Use RSS as fallback when innertube opens\n\n---\n\n## Summary Table: YouTube HTTP Resilience Requirements\n\n| Component | Pattern | Configuration | Notes |\n|-----------|---------|---------------|-------|\n| Rate Limit Detection | Status codes + headers | 429, 503, Retry-After | Respect all signals |\n| Backoff | Exponential + jitter | 1s-30s, 2x multiplier | Critical for stability |\n| Throttling | Token bucket | 2-3 req/s (innertube) | Per-endpoint config |\n| Connection Pool | HTTP transport | 10 max conn/host | Prevents DOS appearance |\n| Sessions | Cookie jar | Persistent storage | Improves reliability |\n| Fallback | Circuit breaker | 5 failures, 30s timeout | Prevents cascades |\n\n---\n\n## Recommended Implementation Order\n\n1. **Phase 1**: HTTP status code detection + Retry-After parsing\n2. **Phase 2**: Exponential backoff with jitter\n3. **Phase 3**: Token bucket rate limiter per endpoint\n4. **Phase 4**: HTTP transport optimization + connection pooling\n5. **Phase 5**: Cookie jar with persistence\n6. **Phase 6**: Circuit breaker pattern\n7. **Phase 7**: Integration tests with live YouTube\n\nThis phased approach allows each component to be tested independently before integration.\n\n---\n\n## References and Key Insights\n\n### YouTube Behavior Observations (from yt-dlp analysis)\n\n1. Rate limiting is aggressive - starts after ~20-30 requests/minute\n2. IP-based blocking can be temporary (5-30 minutes)\n3. Session cookies significantly improve reliability\n4. Realistic User-Agent is non-negotiable\n5. Innertube API is more reliable than scraping (uses fewer heuristics)\n\n### Go Standard Library Best Practices\n\n1. Use `golang.org/x/time/rate` for token bucket\n2. Use `http.Transport` with custom configuration\n3. Use `net/http/cookiejar` for persistence\n4. Use `crypto/rand` for jitter (not math/rand)\n5. Use `context` for timeout/cancellation\n\n### Industry Standards\n\n- RFC 6585: HTTP 429 Too Many Requests specification\n- RFC 7230: HTTP/1.1 Message Syntax (connection management)\n- RFC 7540: HTTP/2 (multiplexing benefits)\n- Exponential backoff with jitter: AWS best practice, widely adopted","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T16:27:26.904827-05:00","updated_at":"2026-01-10T16:41:36.957031-05:00","closed_at":"2026-01-10T16:41:36.957032-05:00","labels":["research","spike"],"dependencies":[{"issue_id":"ytsync-ad3.1","depends_on_id":"ytsync-ad3","type":"parent-child","created_at":"2026-01-10T16:27:26.905365-05:00","created_by":"daemon"}]}
{"id":"ytsync-ad3.10","title":"Integration Tests with YouTube Rate Limiting","description":"Implement integration tests against live YouTube endpoints (with rate limiting safeguards). Test: innertube API throttling, retry behavior under 429 responses, cookie persistence, User-Agent rotation.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T16:40:46.907967-05:00","updated_at":"2026-01-10T16:40:46.907967-05:00","labels":["testing"],"dependencies":[{"issue_id":"ytsync-ad3.10","depends_on_id":"ytsync-ad3","type":"parent-child","created_at":"2026-01-10T16:40:46.911879-05:00","created_by":"daemon"}]}
{"id":"ytsync-ad3.2","title":"Spike: Go HTTP Client Libraries","description":"Evaluate Go HTTP client options:\n- Standard net/http with custom transport\n- resty, req, or similar high-level clients\n- Retry middleware options\n- Cookie jar and session persistence","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T16:27:27.330638-05:00","updated_at":"2026-01-10T16:51:14.583485-05:00","closed_at":"2026-01-10T16:51:14.583489-05:00","labels":["research","spike"],"dependencies":[{"issue_id":"ytsync-ad3.2","depends_on_id":"ytsync-ad3","type":"parent-child","created_at":"2026-01-10T16:27:27.331105-05:00","created_by":"daemon"}]}
{"id":"ytsync-ad3.3","title":"Rate Limit Detection and Status Code Handling","description":"Implement HTTP status code detection for rate limiting (429, 503) and response header parsing for Retry-After. Include detection of YouTube-specific rate limit signals.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T16:40:29.794573-05:00","updated_at":"2026-01-10T16:40:29.794573-05:00","labels":["implementation"],"dependencies":[{"issue_id":"ytsync-ad3.3","depends_on_id":"ytsync-ad3","type":"parent-child","created_at":"2026-01-10T16:40:29.798176-05:00","created_by":"daemon"}]}
{"id":"ytsync-ad3.4","title":"Exponential Backoff with Jitter Implementation","description":"Implement exponential backoff with jitter for retry logic. Configuration: initial 1s, max 30s, multiplier 2.0, jitter +/-20%. Support configurable attempts and thresholds.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T16:40:32.139819-05:00","updated_at":"2026-01-10T16:40:32.139819-05:00","labels":["implementation"],"dependencies":[{"issue_id":"ytsync-ad3.4","depends_on_id":"ytsync-ad3","type":"parent-child","created_at":"2026-01-10T16:40:32.142119-05:00","created_by":"daemon"}]}
{"id":"ytsync-ad3.5","title":"Request Queuing and Token Bucket Rate Limiter","description":"Implement token bucket algorithm for per-domain request throttling using golang.org/x/time/rate. Support configurable rates per endpoint: innertube (2-3 req/s), RSS (no limit), Data API (quota-based).","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T16:40:34.8897-05:00","updated_at":"2026-01-10T16:40:34.8897-05:00","labels":["implementation"],"dependencies":[{"issue_id":"ytsync-ad3.5","depends_on_id":"ytsync-ad3","type":"parent-child","created_at":"2026-01-10T16:40:34.892184-05:00","created_by":"daemon"}]}
{"id":"ytsync-ad3.6","title":"HTTP Connection Pool and Concurrent Request Management","description":"Configure http.Client with optimized transport settings: 10-20 connection pool, 5-10 max concurrent per host, HTTP/2 support, 30s request timeout, 90s idle timeout.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T16:40:38.359674-05:00","updated_at":"2026-01-10T16:40:38.359674-05:00","labels":["implementation"],"dependencies":[{"issue_id":"ytsync-ad3.6","depends_on_id":"ytsync-ad3","type":"parent-child","created_at":"2026-01-10T16:40:38.360229-05:00","created_by":"daemon"}]}
{"id":"ytsync-ad3.7","title":"Session and Cookie Management","description":"Implement persistent cookie jar using http.CookieJar. Support cookie persistence to file for session state across restarts. Configure realistic User-Agent and request headers for YouTube.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T16:40:40.296293-05:00","updated_at":"2026-01-10T16:40:40.296293-05:00","labels":["implementation"],"dependencies":[{"issue_id":"ytsync-ad3.7","depends_on_id":"ytsync-ad3","type":"parent-child","created_at":"2026-01-10T16:40:40.30095-05:00","created_by":"daemon"}]}
{"id":"ytsync-ad3.8","title":"Circuit Breaker Pattern for Fault Tolerance","description":"Implement circuit breaker (Closed/Open/Half-Open states) to fail fast on repeated failures. Thresholds: 5 consecutive failures, 30s recovery timeout, distinguish permanent vs transient errors.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T16:40:42.575094-05:00","updated_at":"2026-01-10T16:40:42.575094-05:00","labels":["implementation"],"dependencies":[{"issue_id":"ytsync-ad3.8","depends_on_id":"ytsync-ad3","type":"parent-child","created_at":"2026-01-10T16:40:42.578736-05:00","created_by":"daemon"}]}
{"id":"ytsync-ad3.9","title":"Unit Tests for HTTP Client Resilience","description":"Implement comprehensive unit tests with mocked HTTP responses: test rate limiting detection, backoff timing, jitter distribution, circuit breaker state transitions, concurrent safety.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T16:40:44.865132-05:00","updated_at":"2026-01-10T16:40:44.865132-05:00","labels":["testing"],"dependencies":[{"issue_id":"ytsync-ad3.9","depends_on_id":"ytsync-ad3","type":"parent-child","created_at":"2026-01-10T16:40:44.865748-05:00","created_by":"daemon"}]}
{"id":"ytsync-qpe","title":"ytsync: Library API \u0026 Public Packages","status":"closed","priority":1,"issue_type":"epic","created_at":"2026-01-10T19:54:26.481435-05:00","updated_at":"2026-01-10T20:09:29.222562-05:00","closed_at":"2026-01-10T20:09:29.222562-05:00","close_reason":"Closed"}
{"id":"ytsync-qpe.1","title":"Move internal packages to public","description":"Move youtube, retry, and config packages out of internal/ to top-level so they can be imported by external packages. This enables using ytsync as a library.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-10T19:54:29.601599-05:00","updated_at":"2026-01-10T20:05:51.57165-05:00","closed_at":"2026-01-10T20:05:51.57165-05:00","close_reason":"Closed","dependencies":[{"issue_id":"ytsync-qpe.1","depends_on_id":"ytsync-qpe","type":"parent-child","created_at":"2026-01-10T19:54:29.604591-05:00","created_by":"daemon"}]}
{"id":"ytsync-qpe.2","title":"Add godoc comments to all exports","description":"Add comprehensive godoc comments to all public types, functions, and interfaces. Include examples where appropriate. Run 'godoc' to verify formatting.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-10T19:54:32.619726-05:00","updated_at":"2026-01-10T20:07:19.578925-05:00","closed_at":"2026-01-10T20:07:19.578925-05:00","close_reason":"Closed","dependencies":[{"issue_id":"ytsync-qpe.2","depends_on_id":"ytsync-qpe","type":"parent-child","created_at":"2026-01-10T19:54:32.623019-05:00","created_by":"daemon"}]}
{"id":"ytsync-qpe.3","title":"Create high-level convenience API","description":"Create ytsync.go with convenience functions: ListVideos(), DownloadVideo(), ExtractTranscript(). These should handle config loading and provide simple interfaces for common operations. Aim for functions that require only context and minimal parameters.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-10T19:54:36.158733-05:00","updated_at":"2026-01-10T20:07:52.45294-05:00","closed_at":"2026-01-10T20:07:52.45294-05:00","close_reason":"Closed","dependencies":[{"issue_id":"ytsync-qpe.3","depends_on_id":"ytsync-qpe","type":"parent-child","created_at":"2026-01-10T19:54:36.1609-05:00","created_by":"daemon"}]}
{"id":"ytsync-qpe.4","title":"Export error types for programmatic handling","description":"Make custom error types (TranscriptError, ListerError, etc.) public so library users can use errors.Is() and errors.As() for error handling. Add Error() methods to all custom error types.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-10T19:54:39.507101-05:00","updated_at":"2026-01-10T20:08:55.803373-05:00","closed_at":"2026-01-10T20:08:55.803373-05:00","close_reason":"Closed","dependencies":[{"issue_id":"ytsync-qpe.4","depends_on_id":"ytsync-qpe","type":"parent-child","created_at":"2026-01-10T19:54:39.509604-05:00","created_by":"daemon"}]}
{"id":"ytsync-qpe.5","title":"Add example code and doc.go","description":"Create doc.go with package overview and examples. Add example_test.go with runnable examples showing: listing videos, extracting transcripts, downloading videos. Examples should be self-contained and testable.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-10T19:54:43.936016-05:00","updated_at":"2026-01-10T20:09:29.034444-05:00","closed_at":"2026-01-10T20:09:29.034444-05:00","close_reason":"Closed","dependencies":[{"issue_id":"ytsync-qpe.5","depends_on_id":"ytsync-qpe","type":"parent-child","created_at":"2026-01-10T19:54:43.937946-05:00","created_by":"daemon"}]}
{"id":"ytsync-rmm","title":"YouTube Channel Video List Discovery","description":"Research and implement the ability to discover and download the list of videos for a YouTube channel. This requires plan-mode analysis with Claude 4.5 to explore YouTube's available APIs, scraping approaches, and rate limiting considerations.","status":"open","priority":1,"issue_type":"epic","created_at":"2026-01-10T16:26:39.006968-05:00","updated_at":"2026-01-10T16:26:39.006968-05:00","labels":["planning","research"]}
{"id":"ytsync-rmm.1","title":"Spike: YouTube Data API vs Scraping Analysis","description":"Plan-mode research spike using Claude 4.5 to analyze:\n- YouTube Data API v3 capabilities and quota limits\n- RSS feed availability for channels\n- Direct HTTP scraping approaches (yt-dlp patterns, innertube API)\n- Rate limiting and anti-bot measures\n- Legal/TOS considerations\n\nDeliverable: Recommendation document with pros/cons of each approach.","notes":"# YouTube Channel Video List Discovery - Research Findings\n\n## Executive Summary\n\nAfter thorough analysis, **the recommended approach is a hybrid strategy**: Use YouTube RSS feeds as the primary method for listing recent videos (simple, free, no auth required), with optional YouTube Data API v3 integration for comprehensive channel data when users provide API keys.\n\n---\n\n## Approach 1: YouTube Data API v3\n\n### Capabilities\n- **Channels.list**: Get channel metadata by ID, username, or handle\n- **PlaylistItems.list**: List videos from a channel's 'uploads' playlist (most reliable method)\n- **Search.list**: Search for videos by channel (expensive, less reliable for complete lists)\n- **Videos.list**: Get detailed video metadata by video ID\n\n### How to List All Channel Videos\n1. Get channel ID via `channels.list`\n2. Extract `contentDetails.relatedPlaylists.uploads` playlist ID\n3. Paginate through `playlistItems.list` with continuation tokens\n4. Optionally enrich with `videos.list` for full metadata\n\n### Quota Limits (Critical Constraint)\n- **Default quota**: 10,000 units/day per project\n- **Cost per operation**:\n  - `channels.list`: 1 unit\n  - `playlistItems.list`: 1 unit (returns 50 items max per page)\n  - `search.list`: 100 units (expensive\\!)\n  - `videos.list`: 1 unit\n- **Practical limits**: ~10,000 video listings/day with basic metadata\n- **Quota increase**: Requires application to Google (often rejected for personal projects)\n\n### Authentication\n- **API Key**: Sufficient for public data (channel videos, metadata)\n- **OAuth 2.0**: Required for private/user-specific data (not needed for this use case)\n- **Setup**: Create project in Google Cloud Console, enable YouTube Data API v3, generate API key\n\n### Pros\n- Official, stable API with clear documentation\n- Structured JSON responses with comprehensive metadata\n- Pagination tokens for reliable iteration\n- No risk of breaking due to website changes\n\n### Cons\n- **Severe quota limitations** - 10K units/day is restrictive for syncing multiple large channels\n- Requires Google Cloud account and API key management\n- Rate limited (queries per second limits on top of daily quota)\n- Cannot access unlisted videos (even own) without OAuth\n\n---\n\n## Approach 2: YouTube RSS Feeds\n\n### Availability\nYouTube provides RSS feeds for every channel at:\n```\nhttps://www.youtube.com/feeds/videos.xml?channel_id=CHANNEL_ID\n```\n\n### Format\n- Standard Atom XML format\n- Contains: video ID, title, author, published date, thumbnail, description\n- Video link, view count (sometimes), and media group info\n\n### Limitations\n- **Only returns 15 most recent videos** (hard limit)\n- No pagination or historical access\n- Limited metadata compared to API\n- Channel ID required (no handle/username resolution)\n\n### Pros\n- **No authentication required**\n- **No rate limits or quotas**\n- Simple to parse (standard Atom XML)\n- Fast and lightweight\n- Works with any HTTP client\n\n### Cons\n- Only 15 videos - useless for initial full sync\n- No way to get older videos\n- Must resolve handles/@username to channel ID separately\n- Limited metadata\n\n---\n\n## Approach 3: Direct HTTP/Scraping (yt-dlp patterns)\n\n### Innertube API\nYouTube's internal API used by the web interface:\n- Endpoint: `https://www.youtube.com/youtubei/v1/browse`\n- Returns JSON with video listings and continuation tokens\n- Used by yt-dlp for channel extraction\n\n### How yt-dlp Does It\n1. Fetch channel page HTML to extract initial data JSON\n2. Parse `ytInitialData` embedded in page\n3. Use continuation tokens to paginate through all videos\n4. Make POST requests to innertube browse endpoint with continuation\n\n### Key Patterns\n- **Client context**: Must send proper client name/version in requests\n- **Continuation tokens**: Opaque tokens for pagination (base64 encoded protobuf)\n- **Tabs**: Videos are in the 'videos' tab, need to navigate tabs\n- **Sorts**: Can sort by 'newest' or 'popular'\n\n### Rate Limiting \u0026 Anti-Bot\n- YouTube uses fingerprinting and behavioral analysis\n- Too many requests trigger CAPTCHA or temporary blocks\n- Recommended: 1-2 second delays between requests\n- Headers must mimic browser (User-Agent, Accept-Language, etc.)\n- Cookie/session management may improve reliability\n- IP-based rate limiting (shared IPs more likely to be blocked)\n\n### Pros\n- **No quota limits** (within reason)\n- **Access to ALL videos** including historical\n- No API key or account needed\n- Same approach as yt-dlp (battle-tested)\n\n### Cons\n- **Fragile** - YouTube changes innertube API without notice\n- Complex to implement correctly\n- Risk of IP blocking\n- Must maintain compatibility with YouTube changes\n- **TOS violation** (see legal section)\n\n---\n\n## Approach 4: Use yt-dlp as Subprocess\n\n### Method\nShell out to yt-dlp with `--flat-playlist` flag:\n```bash\nyt-dlp --flat-playlist -J \"https://www.youtube.com/@channel/videos\"\n```\n\n### Pros\n- Battle-tested extraction logic\n- Maintained by active community\n- Handles edge cases and YouTube changes\n- JSON output with `-J` flag\n- Already handles rate limiting internally\n\n### Cons\n- External dependency (yt-dlp must be installed)\n- Subprocess overhead\n- Less control over retry logic\n- Still subject to same rate limits/blocks\n- Output format may change between versions\n\n---\n\n## Legal/TOS Considerations\n\n### YouTube Terms of Service\n- **Section 5.1**: Prohibits accessing service through automated means except via YouTube API\n- **Scraping is technically TOS violation**\n- yt-dlp exists in legal gray area (no major enforcement against users)\n\n### Practical Reality\n- Google rarely pursues individual developers\n- yt-dlp has millions of users without legal issues\n- Commercial use of scraped data is higher risk\n- Personal/educational use is lower risk\n\n### API Terms\n- API use is compliant but quota-limited\n- Must display YouTube branding per API ToS\n- Cannot cache data longer than 30 days without refresh\n\n### Recommendation\n- For open-source/personal tool: Scraping is acceptable pragmatically\n- For commercial product: Use only official API\n- Always implement respectful rate limiting regardless of approach\n\n---\n\n## Recommended Hybrid Strategy\n\n### Primary: RSS Feed + Scraping Fallback\n\n1. **RSS Feed First** (for recent/incremental syncs)\n   - Fast, free, no auth\n   - Perfect for staying up-to-date with new videos\n   - Use for channels already synced\n\n2. **Innertube Scraping** (for initial full sync)\n   - Port yt-dlp's channel extraction logic to Go\n   - Or shell out to yt-dlp as subprocess\n   - Use for first-time channel sync to get historical videos\n\n3. **Optional YouTube API** (for users with API keys)\n   - Support API key configuration\n   - Use when user provides key and wants official route\n   - Better metadata, more reliable\n\n### Implementation Priority\n\n1. **Phase 1**: RSS feed implementation (quick win, handles incremental sync)\n2. **Phase 2**: yt-dlp subprocess integration (full channel sync capability)\n3. **Phase 3**: Optional YouTube Data API support (for power users)\n\n### Architecture Notes\n\n- Abstract behind `VideoLister` interface\n- Allow runtime selection of strategy\n- Implement robust retry with exponential backoff\n- Cache channel ID resolution\n- Store 'last synced' timestamp per channel\n\n---\n\n## Key Metrics for Decision\n\n| Approach | Quota | Auth Required | Videos Returned | Reliability | Complexity |\n|----------|-------|---------------|-----------------|-------------|------------|\n| RSS Feed | None | No | 15 recent | High | Low |\n| Data API | 10K/day | API Key | All | Very High | Medium |\n| Scraping | None* | No | All | Medium | High |\n| yt-dlp | None* | No | All | High | Low |\n\n*Subject to rate limiting and potential blocking\n\n---\n\n## Final Recommendation\n\n**Start with yt-dlp subprocess approach** for the MVP:\n- Fastest to implement\n- Battle-tested reliability\n- Access to all videos\n- Can be replaced with native Go implementation later\n\nAdd RSS feeds for efficient incremental syncs after initial implementation.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-10T16:26:53.253246-05:00","updated_at":"2026-01-10T16:36:14.809991-05:00","closed_at":"2026-01-10T16:36:14.809999-05:00","labels":["opus-4.5","research","spike"],"dependencies":[{"issue_id":"ytsync-rmm.1","depends_on_id":"ytsync-rmm","type":"parent-child","created_at":"2026-01-10T16:26:53.257033-05:00","created_by":"daemon"}]}
{"id":"ytsync-rmm.10","title":"Configuration for yt-dlp Path and Options","description":"Implement configuration management for yt-dlp and extraction options.\n\n## Configuration Options\n\n### yt-dlp Settings\n- ytdlp_path: Path to yt-dlp binary (default: search PATH)\n- ytdlp_timeout: Timeout for extraction (default: 5 minutes)\n- ytdlp_rate_limit: Delay between requests (default: 1 second)\n\n### Extraction Settings\n- max_videos: Maximum videos to fetch (0 = unlimited)\n- include_shorts: Whether to include YouTube Shorts (default: true)\n- include_live: Whether to include live streams (default: true)\n- date_after: Only fetch videos after this date\n- date_before: Only fetch videos before this date\n\n### Retry Settings\n- max_retries: Maximum retry attempts (default: 5)\n- initial_backoff: Initial backoff duration (default: 1s)\n- max_backoff: Maximum backoff duration (default: 30s)\n\n## Configuration Sources (priority order)\n1. Command line flags\n2. Environment variables (YTSYNC_YTDLP_PATH, etc.)\n3. Config file (ytsync.yaml or ytsync.json)\n4. Defaults\n\n## Implementation\n- Use viper or similar for config management\n- Define Config struct with validation\n- Support config file in current directory or home directory\n- Provide config validation at startup\n\n## Acceptance Criteria\n- All options configurable via env vars\n- Config file loading works\n- Invalid config produces clear error messages\n- Default values documented\n- Example config file provided","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T16:35:53.674229-05:00","updated_at":"2026-01-10T18:26:20.906742-05:00","closed_at":"2026-01-10T18:26:20.906742-05:00","close_reason":"Closed","labels":["implementation"],"dependencies":[{"issue_id":"ytsync-rmm.10","depends_on_id":"ytsync-rmm","type":"parent-child","created_at":"2026-01-10T16:35:53.677229-05:00","created_by":"daemon"}]}
{"id":"ytsync-rmm.11","title":"Optional YouTube Data API v3 Integration","description":"Implement optional YouTube Data API v3 support for users with API keys.\n\n## Overview\nThis is a lower priority enhancement for users who prefer the official API route and have quota available.\n\n## Requirements\n- Implement VideoLister interface using YouTube Data API v3\n- Support API key configuration\n- Handle quota exhaustion gracefully\n- Fall back to yt-dlp when quota exceeded\n\n## API Operations Needed\n1. channels.list - Resolve channel URL to ID and get uploads playlist ID\n2. playlistItems.list - Paginate through uploads playlist\n3. videos.list - Optional enrichment for full metadata\n\n## Configuration\n- youtube_api_key: API key (from env or config)\n- youtube_api_enabled: Enable/disable API usage\n- youtube_api_quota_reserve: Stop using API when quota below threshold\n\n## Implementation Details\n- Use google-api-go-client/youtube/v3\n- Implement pagination with nextPageToken\n- Track quota usage locally (reset daily)\n- Log quota consumption for user awareness\n\n## Quota Management\n- channels.list: 1 unit\n- playlistItems.list: 1 unit per page (50 videos)\n- videos.list: 1 unit per call (50 video IDs)\n- Default quota: 10,000 units/day\n\n## Acceptance Criteria\n- API integration works when key provided\n- Graceful degradation when quota exhausted\n- Clear logging of quota usage\n- Documentation on obtaining API key\n- Can be completely disabled via config","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T16:36:04.195559-05:00","updated_at":"2026-01-10T16:36:04.195559-05:00","labels":["enhancement","implementation"],"dependencies":[{"issue_id":"ytsync-rmm.11","depends_on_id":"ytsync-rmm","type":"parent-child","created_at":"2026-01-10T16:36:04.19875-05:00","created_by":"daemon"}]}
{"id":"ytsync-rmm.12","title":"Implement Innertube Continuation Token Handler","description":"Implement Go code to handle Innertube API continuation tokens for paginating through large channel video lists. Handle token expiry, implement exponential backoff for rate limiting, and support resumable syncs.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T16:41:11.754683-05:00","updated_at":"2026-01-10T16:41:11.754683-05:00","labels":["implementation"],"dependencies":[{"issue_id":"ytsync-rmm.12","depends_on_id":"ytsync-rmm","type":"parent-child","created_at":"2026-01-10T16:41:11.757724-05:00","created_by":"daemon"}]}
{"id":"ytsync-rmm.13","title":"Implement Pagination State Storage Schema","description":"Design and implement database schema for storing pagination state per channel. Must support: continuation tokens with expiry, last sync timestamps, items processed counts, and resumable sync capability across all pagination strategies.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T16:41:15.791-05:00","updated_at":"2026-01-10T16:41:15.791-05:00","labels":["implementation"],"dependencies":[{"issue_id":"ytsync-rmm.13","depends_on_id":"ytsync-rmm","type":"parent-child","created_at":"2026-01-10T16:41:15.793227-05:00","created_by":"daemon"}]}
{"id":"ytsync-rmm.14","title":"Implement RSS Feed Incremental Sync Strategy","description":"Implement efficient incremental sync using RSS feeds after initial full sync. Filter new videos by last_sync_timestamp, handle channel updates with variable frequency, and implement fallback to full sync if gaps detected.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T16:41:16.172228-05:00","updated_at":"2026-01-10T16:41:16.172228-05:00","labels":["implementation"],"dependencies":[{"issue_id":"ytsync-rmm.14","depends_on_id":"ytsync-rmm","type":"parent-child","created_at":"2026-01-10T16:41:16.17276-05:00","created_by":"daemon"}]}
{"id":"ytsync-rmm.15","title":"Implement Rate Limiting and Backoff for Innertube","description":"Implement exponential backoff strategy for Innertube pagination requests: 1s → 2s → 4s → 8s delays on 429/403 responses. Add request throttling to prevent anti-bot detection. Track IP-based rate limits across sessions.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T16:41:16.562834-05:00","updated_at":"2026-01-10T16:41:16.562834-05:00","labels":["implementation"],"dependencies":[{"issue_id":"ytsync-rmm.15","depends_on_id":"ytsync-rmm","type":"parent-child","created_at":"2026-01-10T16:41:16.563338-05:00","created_by":"daemon"}]}
{"id":"ytsync-rmm.16","title":"Support YouTube Data API v3 Pagination Tokens","description":"Implement optional YouTube Data API v3 support for users with API keys. Use playlistItems.list with pageToken pagination. Handle quota constraints (10K units/day). Support save/resume of pageToken for interrupted syncs.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T16:41:19.637214-05:00","updated_at":"2026-01-10T16:41:19.637214-05:00","labels":["implementation"],"dependencies":[{"issue_id":"ytsync-rmm.16","depends_on_id":"ytsync-rmm","type":"parent-child","created_at":"2026-01-10T16:41:19.637812-05:00","created_by":"daemon"}]}
{"id":"ytsync-rmm.2","title":"Spike: Channel ID Resolution","description":"Research how to resolve various YouTube channel URL formats to canonical channel IDs:\n- /channel/UC... format\n- /c/CustomName format  \n- /@handle format\n- Legacy /user/ format\n\nUnderstand which formats work with which APIs/approaches.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T16:26:53.657132-05:00","updated_at":"2026-01-10T16:51:14.389536-05:00","closed_at":"2026-01-10T16:51:14.389541-05:00","labels":["research","spike"],"dependencies":[{"issue_id":"ytsync-rmm.2","depends_on_id":"ytsync-rmm","type":"parent-child","created_at":"2026-01-10T16:26:53.657662-05:00","created_by":"daemon"}]}
{"id":"ytsync-rmm.3","title":"Spike: Video List Pagination Strategies","description":"Research pagination approaches for large channels:\n- API pagination tokens\n- Continuation tokens for scraping\n- Handling channels with 1000+ videos\n- Incremental sync strategies (only fetch new videos)","notes":"Pagination Spike Research Complete","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T16:26:54.060324-05:00","updated_at":"2026-01-10T16:41:22.109936-05:00","closed_at":"2026-01-10T16:41:22.109939-05:00","labels":["research","spike"],"dependencies":[{"issue_id":"ytsync-rmm.3","depends_on_id":"ytsync-rmm","type":"parent-child","created_at":"2026-01-10T16:26:54.060846-05:00","created_by":"daemon"}]}
{"id":"ytsync-rmm.4","title":"Implement yt-dlp Video List Extraction","description":"Implement video list extraction using yt-dlp as a subprocess.\n\n## Requirements\n- Create a Go wrapper for yt-dlp subprocess execution\n- Use `--flat-playlist -J` flags to get JSON video list\n- Parse yt-dlp JSON output into Go structs\n- Support channel URLs in various formats (@handle, /channel/ID, /c/name)\n- Extract: video ID, title, published date, duration, description\n\n## Implementation Details\n- Use `os/exec` to run yt-dlp\n- Capture stdout and parse as JSON\n- Handle stderr for error messages\n- Implement timeout for long-running extractions\n- Support cancellation via context\n\n## Acceptance Criteria\n- [ ] Can extract video list from channel URL\n- [ ] Returns structured VideoInfo slice\n- [ ] Handles yt-dlp not installed gracefully\n- [ ] Respects context cancellation\n- [ ] Timeout after configurable duration","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T16:34:51.007952-05:00","updated_at":"2026-01-10T18:10:58.404816-05:00","closed_at":"2026-01-10T18:10:58.404816-05:00","close_reason":"Closed","labels":["implementation"],"dependencies":[{"issue_id":"ytsync-rmm.4","depends_on_id":"ytsync-rmm","type":"parent-child","created_at":"2026-01-10T16:34:51.009966-05:00","created_by":"daemon"}]}
{"id":"ytsync-rmm.5","title":"Implement RSS Feed Video Fetcher","description":"Implement RSS feed fetching for incremental video sync.\n\n## Requirements\n- Fetch YouTube RSS feed: `https://www.youtube.com/feeds/videos.xml?channel_id=CHANNEL_ID`\n- Parse Atom XML format into Go structs\n- Extract: video ID, title, published date, thumbnail URL, description\n- Handle network errors gracefully\n\n## Implementation Details\n- Use standard `net/http` for fetching\n- Use `encoding/xml` for parsing Atom feed\n- Define Atom XML structs matching YouTube's feed format\n- Support ETag/If-Modified-Since for efficient polling\n\n## Limitations to Document\n- Only returns 15 most recent videos\n- Requires channel ID (not handles)\n- Use in conjunction with full sync for comprehensive coverage\n\n## Acceptance Criteria\n- [ ] Can fetch and parse RSS feed given channel ID\n- [ ] Returns VideoInfo slice compatible with yt-dlp extractor\n- [ ] Handles HTTP errors (404, 500, network timeout)\n- [ ] Supports conditional requests for efficiency","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T16:34:59.793156-05:00","updated_at":"2026-01-10T18:09:37.673194-05:00","closed_at":"2026-01-10T18:09:37.673194-05:00","close_reason":"Closed","labels":["implementation"],"dependencies":[{"issue_id":"ytsync-rmm.5","depends_on_id":"ytsync-rmm","type":"parent-child","created_at":"2026-01-10T16:34:59.793757-05:00","created_by":"daemon"}]}
{"id":"ytsync-rmm.6","title":"Implement Error Handling and Retry Logic","description":"Implement robust error handling and retry logic for video list operations.\n\n## Requirements\n- Exponential backoff with jitter for transient failures\n- Configurable retry count and delays\n- Distinguish between retryable and permanent errors\n- Rate limit detection and handling\n- Circuit breaker pattern for repeated failures\n\n## Error Categories\n1. **Retryable**: Network timeout, 429 rate limit, 503 service unavailable\n2. **Permanent**: 404 channel not found, 403 private channel, invalid URL\n3. **Transient**: Connection reset, DNS failure\n\n## Implementation Details\n- Create `retry.Retry` function with backoff configuration\n- Define custom error types for categorization\n- Implement rate limiter using `golang.org/x/time/rate`\n- Add jitter to prevent thundering herd\n- Log retry attempts with context\n\n## Backoff Strategy\n- Initial delay: 1 second\n- Max delay: 30 seconds\n- Multiplier: 2x\n- Jitter: +/- 20%\n- Max retries: 5 for network errors, 0 for permanent errors\n\n## Acceptance Criteria\n- [ ] Retries transient errors with exponential backoff\n- [ ] Does not retry permanent errors\n- [ ] Respects rate limits with appropriate delays\n- [ ] Circuit breaker opens after N consecutive failures\n- [ ] All retry attempts are logged","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T16:35:08.013128-05:00","updated_at":"2026-01-10T18:26:20.908702-05:00","closed_at":"2026-01-10T18:26:20.908702-05:00","close_reason":"Closed","labels":["implementation"],"dependencies":[{"issue_id":"ytsync-rmm.6","depends_on_id":"ytsync-rmm","type":"parent-child","created_at":"2026-01-10T16:35:08.015993-05:00","created_by":"daemon"}]}
{"id":"ytsync-rmm.7","title":"Define VideoLister Interface and Models","description":"Define the core interface and data models for video list extraction.\n\n## Interface Definition\n```go\ntype VideoLister interface {\n    ListVideos(ctx context.Context, channelURL string) ([]VideoInfo, error)\n    SupportsFullHistory() bool\n}\n\ntype VideoInfo struct {\n    ID          string\n    Title       string\n    ChannelID   string\n    ChannelName string\n    Published   time.Time\n    Duration    time.Duration  // may be 0 for some sources\n    Description string\n    Thumbnail   string\n}\n```\n\n## Requirements\n- Define VideoLister interface for strategy pattern\n- Define VideoInfo struct with common fields\n- Define ListOptions for pagination/filtering\n- Define error types for common failure modes\n\n## Error Types\n- ErrChannelNotFound\n- ErrRateLimited  \n- ErrNetworkTimeout\n- ErrInvalidURL\n- ErrYtdlpNotInstalled\n\n## Design Decisions\n- Interface allows swapping implementations (yt-dlp, RSS, API)\n- VideoInfo is the common currency between components\n- Errors are typed for programmatic handling\n\n## Acceptance Criteria\n- [ ] Interface defined in youtube/lister.go\n- [ ] VideoInfo struct with JSON tags\n- [ ] Custom error types defined\n- [ ] Documentation comments on all exports","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T16:35:16.803052-05:00","updated_at":"2026-01-10T18:07:52.251834-05:00","closed_at":"2026-01-10T18:07:52.251834-05:00","close_reason":"Closed","labels":["implementation"],"dependencies":[{"issue_id":"ytsync-rmm.7","depends_on_id":"ytsync-rmm","type":"parent-child","created_at":"2026-01-10T16:35:16.806656-05:00","created_by":"daemon"}]}
{"id":"ytsync-rmm.8","title":"Unit Tests for Video List Fetching","description":"Implement comprehensive unit tests for video list extraction components.\n\n## Test Coverage Required\n\n### yt-dlp Extractor Tests\n- Mock subprocess execution with canned responses\n- Test JSON parsing of yt-dlp output\n- Test error handling when yt-dlp not installed\n- Test timeout handling\n- Test various channel URL formats\n\n### RSS Feed Tests\n- Mock HTTP responses with sample Atom XML\n- Test XML parsing edge cases\n- Test handling of missing fields\n- Test HTTP error responses (404, 500)\n- Test conditional request headers\n\n### Retry Logic Tests\n- Test exponential backoff timing\n- Test jitter distribution\n- Test retry count limits\n- Test error categorization\n- Test circuit breaker behavior\n\n## Test Data\n- Create testdata directory with sample responses\n- Include edge cases: empty channels, unicode titles, long descriptions\n\n## Mocking Strategy\n- Use interfaces for HTTP client (inject mock)\n- Use exec.Command wrapper for yt-dlp (inject mock)\n- Use table-driven tests for multiple scenarios\n\n## Acceptance Criteria\n- 80 percent code coverage on lister implementations\n- All error paths tested\n- Edge cases documented and tested\n- Tests run without network access\n- Tests complete in under 10 seconds","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T16:35:34.67875-05:00","updated_at":"2026-01-10T18:26:20.909979-05:00","closed_at":"2026-01-10T18:26:20.909979-05:00","close_reason":"Closed","labels":["testing"],"dependencies":[{"issue_id":"ytsync-rmm.8","depends_on_id":"ytsync-rmm","type":"parent-child","created_at":"2026-01-10T16:35:34.682107-05:00","created_by":"daemon"}]}
{"id":"ytsync-rmm.9","title":"Integration Tests for Video List Fetching","description":"Implement integration tests that verify end-to-end video list extraction.\n\n## Integration Test Scope\n\n### Live Service Tests (tagged for CI skip)\n- Test against known stable YouTube channels\n- Verify yt-dlp subprocess integration works\n- Verify RSS feed fetching works\n- Use channels unlikely to change (e.g., official YouTube channels)\n\n### Docker-based Tests\n- Create test container with yt-dlp installed\n- Verify subprocess works in containerized environment\n- Test with various yt-dlp versions\n\n### End-to-End Scenarios\n1. Full channel sync of small test channel\n2. Incremental sync using RSS\n3. Retry behavior under simulated failures\n4. Handle channel with no videos\n5. Handle very large channel (pagination)\n\n## Test Channels\n- Use official YouTube Help channel (stable, public)\n- Create test fixtures for expected video counts\n\n## CI Configuration\n- Integration tests tagged with build tag\n- Run on schedule, not every commit\n- Allow network access in CI environment\n\n## Acceptance Criteria\n- Integration tests pass against live YouTube\n- Tests are idempotent and can run repeatedly\n- Flaky tests are marked and tracked\n- Test execution time under 60 seconds\n- Clear documentation on running integration tests","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T16:35:44.585733-05:00","updated_at":"2026-01-10T16:35:44.585733-05:00","labels":["testing"],"dependencies":[{"issue_id":"ytsync-rmm.9","depends_on_id":"ytsync-rmm","type":"parent-child","created_at":"2026-01-10T16:35:44.58893-05:00","created_by":"daemon"}]}
{"id":"ytsync-uff","title":"Storage Service Design","description":"Design and implement an abstracted storage service for tracking sync state, video metadata, and transcript data. Start simple with JSON file storage but architect for future extension to other backends (SQLite, cloud storage, etc.).","status":"closed","priority":1,"issue_type":"epic","created_at":"2026-01-10T16:26:39.40174-05:00","updated_at":"2026-01-10T18:07:08.095737-05:00","closed_at":"2026-01-10T18:07:08.095737-05:00","close_reason":"Closed","labels":["architecture","planning"]}
{"id":"ytsync-uff.1","title":"Spike: Storage Interface Design","description":"Plan-mode design spike for the storage abstraction layer:\n- Define Go interfaces for storage operations (CRUD for channels, videos, transcripts)\n- Design schema for tracking sync state (last sync time, video counts, errors)\n- Consider future backends: JSON file, SQLite, cloud storage\n- Error handling and recovery patterns\n\nDeliverable: Interface definitions and JSON schema draft.","notes":"# Storage Interface Design\n\n## Overview\n\nThis spike defines the storage abstraction layer for ytsync, a Go application for syncing YouTube channel videos and extracting transcripts. The design prioritizes clean Go idioms, extensibility, and safe concurrent access.\n\n## Core Interfaces\n\n### 1. Primary Storage Interface\n\n```go\npackage storage\n\nimport (\n    \"context\"\n    \"time\"\n)\n\n// Store is the main storage interface for all ytsync data operations.\n// Implementations must be safe for concurrent use.\ntype Store interface {\n    ChannelStore\n    VideoStore\n    TranscriptStore\n    SyncStateStore\n    \n    // Close releases any resources held by the store\n    Close() error\n}\n\n// ChannelStore handles channel CRUD operations\ntype ChannelStore interface {\n    CreateChannel(ctx context.Context, channel *Channel) error\n    GetChannel(ctx context.Context, id string) (*Channel, error)\n    GetChannelByYouTubeID(ctx context.Context, youtubeID string) (*Channel, error)\n    UpdateChannel(ctx context.Context, channel *Channel) error\n    DeleteChannel(ctx context.Context, id string) error\n    ListChannels(ctx context.Context) ([]*Channel, error)\n}\n\n// VideoStore handles video CRUD operations\ntype VideoStore interface {\n    CreateVideo(ctx context.Context, video *Video) error\n    GetVideo(ctx context.Context, id string) (*Video, error)\n    GetVideoByYouTubeID(ctx context.Context, youtubeID string) (*Video, error)\n    UpdateVideo(ctx context.Context, video *Video) error\n    DeleteVideo(ctx context.Context, id string) error\n    ListVideosByChannel(ctx context.Context, channelID string) ([]*Video, error)\n    ListVideosNeedingTranscript(ctx context.Context) ([]*Video, error)\n}\n\n// TranscriptStore handles transcript CRUD operations\ntype TranscriptStore interface {\n    CreateTranscript(ctx context.Context, transcript *Transcript) error\n    GetTranscript(ctx context.Context, videoID string) (*Transcript, error)\n    UpdateTranscript(ctx context.Context, transcript *Transcript) error\n    DeleteTranscript(ctx context.Context, videoID string) error\n    ListTranscriptsByChannel(ctx context.Context, channelID string) ([]*Transcript, error)\n}\n\n// SyncStateStore handles sync state operations\ntype SyncStateStore interface {\n    GetSyncState(ctx context.Context, channelID string) (*SyncState, error)\n    UpdateSyncState(ctx context.Context, state *SyncState) error\n    GetLastSync(ctx context.Context, channelID string) (time.Time, error)\n}\n```\n\n### 2. Data Models\n\n```go\npackage storage\n\nimport \"time\"\n\n// Channel represents a YouTube channel being tracked\ntype Channel struct {\n    ID          string    `json:\"id\"`           // Internal UUID\n    YouTubeID   string    `json:\"youtube_id\"`   // YouTube channel ID (UC...)\n    Name        string    `json:\"name\"`\n    Description string    `json:\"description,omitempty\"`\n    URL         string    `json:\"url\"`\n    CreatedAt   time.Time `json:\"created_at\"`\n    UpdatedAt   time.Time `json:\"updated_at\"`\n}\n\n// Video represents a YouTube video\ntype Video struct {\n    ID            string    `json:\"id\"`              // Internal UUID\n    YouTubeID     string    `json:\"youtube_id\"`      // YouTube video ID\n    ChannelID     string    `json:\"channel_id\"`      // FK to Channel.ID\n    Title         string    `json:\"title\"`\n    Description   string    `json:\"description,omitempty\"`\n    PublishedAt   time.Time `json:\"published_at\"`\n    Duration      int       `json:\"duration\"`        // seconds\n    HasTranscript bool      `json:\"has_transcript\"`\n    CreatedAt     time.Time `json:\"created_at\"`\n    UpdatedAt     time.Time `json:\"updated_at\"`\n}\n\n// Transcript represents a video transcript\ntype Transcript struct {\n    VideoID    string     `json:\"video_id\"`    // FK to Video.ID\n    Language   string     `json:\"language\"`    // e.g., \"en\", \"auto\"\n    Content    string     `json:\"content\"`     // Plain text content\n    Segments   []Segment  `json:\"segments,omitempty\"` // Timed segments if available\n    Source     string     `json:\"source\"`      // \"youtube\", \"whisper\", etc.\n    CreatedAt  time.Time  `json:\"created_at\"`\n    UpdatedAt  time.Time  `json:\"updated_at\"`\n}\n\n// Segment represents a timed transcript segment\ntype Segment struct {\n    Start float64 `json:\"start\"` // seconds\n    End   float64 `json:\"end\"`   // seconds\n    Text  string  `json:\"text\"`\n}\n\n// SyncState tracks synchronization progress for a channel\ntype SyncState struct {\n    ChannelID       string    `json:\"channel_id\"`\n    LastSyncAt      time.Time `json:\"last_sync_at\"`\n    LastVideoID     string    `json:\"last_video_id,omitempty\"`    // For pagination\n    VideosProcessed int       `json:\"videos_processed\"`\n    TotalVideos     int       `json:\"total_videos\"`\n    Status          string    `json:\"status\"`  // \"idle\", \"syncing\", \"error\"\n    LastError       string    `json:\"last_error,omitempty\"`\n}\n```\n\n## JSON File Schema\n\n```json\n{\n  \"version\": \"1.0\",\n  \"updated_at\": \"2025-01-10T12:00:00Z\",\n  \"channels\": {\n    \"\u003cchannel-id\u003e\": { ...channel object... }\n  },\n  \"videos\": {\n    \"\u003cvideo-id\u003e\": { ...video object... }\n  },\n  \"transcripts\": {\n    \"\u003cvideo-id\u003e\": { ...transcript object... }\n  },\n  \"sync_states\": {\n    \"\u003cchannel-id\u003e\": { ...sync state object... }\n  },\n  \"indexes\": {\n    \"youtube_channel_id\": { \"\u003cyoutube-id\u003e\": \"\u003cchannel-id\u003e\" },\n    \"youtube_video_id\": { \"\u003cyoutube-id\u003e\": \"\u003cvideo-id\u003e\" },\n    \"videos_by_channel\": { \"\u003cchannel-id\u003e\": [\"\u003cvideo-id\u003e\", ...] }\n  }\n}\n```\n\n## Error Handling Patterns\n\n```go\npackage storage\n\nimport \"errors\"\n\n// Sentinel errors for common conditions\nvar (\n    ErrNotFound        = errors.New(\"storage: not found\")\n    ErrAlreadyExists   = errors.New(\"storage: already exists\")\n    ErrInvalidInput    = errors.New(\"storage: invalid input\")\n    ErrStorageCorrupt  = errors.New(\"storage: data corruption detected\")\n    ErrLockTimeout     = errors.New(\"storage: lock acquisition timeout\")\n)\n\n// StorageError wraps errors with context\ntype StorageError struct {\n    Op      string // Operation: \"create\", \"read\", \"update\", \"delete\"\n    Entity  string // Entity type: \"channel\", \"video\", \"transcript\"\n    ID      string // Entity ID if applicable\n    Err     error  // Underlying error\n}\n\nfunc (e *StorageError) Error() string {\n    if e.ID != \"\" {\n        return fmt.Sprintf(\"storage: %s %s %s: %v\", e.Op, e.Entity, e.ID, e.Err)\n    }\n    return fmt.Sprintf(\"storage: %s %s: %v\", e.Op, e.Entity, e.Err)\n}\n\nfunc (e *StorageError) Unwrap() error { return e.Err }\n```\n\n## Atomic Write Pattern\n\n```go\npackage storage\n\nimport (\n    \"os\"\n    \"path/filepath\"\n)\n\n// AtomicWriter provides atomic file write operations using temp file + rename\ntype AtomicWriter struct {\n    path    string\n    tmpPath string\n    file    *os.File\n}\n\n// NewAtomicWriter creates a writer for atomic file updates\nfunc NewAtomicWriter(path string) (*AtomicWriter, error) {\n    dir := filepath.Dir(path)\n    tmpFile, err := os.CreateTemp(dir, \".ytsync-*.tmp\")\n    if err != nil {\n        return nil, fmt.Errorf(\"create temp file: %w\", err)\n    }\n    return \u0026AtomicWriter{\n        path:    path,\n        tmpPath: tmpFile.Name(),\n        file:    tmpFile,\n    }, nil\n}\n\nfunc (w *AtomicWriter) Write(p []byte) (n int, err error) {\n    return w.file.Write(p)\n}\n\n// Commit atomically replaces the target file\nfunc (w *AtomicWriter) Commit() error {\n    if err := w.file.Sync(); err != nil {\n        return fmt.Errorf(\"sync: %w\", err)\n    }\n    if err := w.file.Close(); err != nil {\n        return fmt.Errorf(\"close: %w\", err)\n    }\n    if err := os.Rename(w.tmpPath, w.path); err != nil {\n        os.Remove(w.tmpPath) // Best effort cleanup\n        return fmt.Errorf(\"rename: %w\", err)\n    }\n    return nil\n}\n\n// Abort discards the temporary file\nfunc (w *AtomicWriter) Abort() error {\n    w.file.Close()\n    return os.Remove(w.tmpPath)\n}\n```\n\n## File Locking\n\n```go\npackage storage\n\nimport (\n    \"os\"\n    \"syscall\"\n    \"time\"\n)\n\n// FileLock provides advisory file locking\ntype FileLock struct {\n    path string\n    file *os.File\n}\n\n// NewFileLock creates a file lock (does not acquire it)\nfunc NewFileLock(path string) *FileLock {\n    return \u0026FileLock{path: path + \".lock\"}\n}\n\n// Lock acquires an exclusive lock with timeout\nfunc (l *FileLock) Lock(timeout time.Duration) error {\n    var err error\n    l.file, err = os.OpenFile(l.path, os.O_CREATE|os.O_RDWR, 0600)\n    if err != nil {\n        return fmt.Errorf(\"open lock file: %w\", err)\n    }\n    \n    deadline := time.Now().Add(timeout)\n    for time.Now().Before(deadline) {\n        err = syscall.Flock(int(l.file.Fd()), syscall.LOCK_EX|syscall.LOCK_NB)\n        if err == nil {\n            return nil\n        }\n        time.Sleep(10 * time.Millisecond)\n    }\n    l.file.Close()\n    return ErrLockTimeout\n}\n\n// Unlock releases the lock\nfunc (l *FileLock) Unlock() error {\n    if l.file == nil {\n        return nil\n    }\n    syscall.Flock(int(l.file.Fd()), syscall.LOCK_UN)\n    l.file.Close()\n    os.Remove(l.path)\n    l.file = nil\n    return nil\n}\n```\n\n## JSON Store Implementation Structure\n\n```go\npackage storage\n\n// JSONStore implements Store using a single JSON file\ntype JSONStore struct {\n    path     string\n    lock     *FileLock\n    data     *storeData\n    mu       sync.RWMutex\n}\n\ntype storeData struct {\n    Version    string                     `json:\"version\"`\n    UpdatedAt  time.Time                  `json:\"updated_at\"`\n    Channels   map[string]*Channel        `json:\"channels\"`\n    Videos     map[string]*Video          `json:\"videos\"`\n    Transcripts map[string]*Transcript    `json:\"transcripts\"`\n    SyncStates map[string]*SyncState      `json:\"sync_states\"`\n    Indexes    *indexes                   `json:\"indexes\"`\n}\n\ntype indexes struct {\n    YouTubeChannelID map[string]string   `json:\"youtube_channel_id\"`\n    YouTubeVideoID   map[string]string   `json:\"youtube_video_id\"`\n    VideosByChannel  map[string][]string `json:\"videos_by_channel\"`\n}\n\nfunc NewJSONStore(path string) (*JSONStore, error) { ... }\nfunc (s *JSONStore) load() error { ... }\nfunc (s *JSONStore) save() error { ... } // Uses AtomicWriter\n```\n\n## Future Extensibility\n\nThe interface-based design allows easy addition of:\n1. **SQLite backend**: Implement Store interface with sql.DB\n2. **Cloud storage**: S3/GCS with local cache layer\n3. **Caching layer**: Wrap any Store with in-memory cache\n4. **Migration support**: Version field enables schema migrations\n\n## Key Design Decisions\n\n1. **Context in all methods**: Enables cancellation and timeouts\n2. **Pointer returns**: Consistent nil for not-found vs empty struct\n3. **Separate sub-interfaces**: Allows testing individual concerns\n4. **Internal UUIDs**: Decouple from YouTube IDs for flexibility\n5. **Explicit indexes**: Maintain lookup performance in JSON\n6. **sync.RWMutex**: Allow concurrent reads, exclusive writes\n7. **Advisory file locks**: Prevent corruption from multiple processes\n\n## Recommended Package Structure\n\n```\nytsync/\n  internal/\n    storage/\n      storage.go      # Interfaces and errors\n      models.go       # Data model structs\n      json_store.go   # JSON file implementation\n      atomic.go       # AtomicWriter utility\n      filelock.go     # FileLock utility\n      json_store_test.go\n      integration_test.go\n```\n","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-10T16:27:05.570885-05:00","updated_at":"2026-01-10T16:38:49.697845-05:00","closed_at":"2026-01-10T16:38:49.697847-05:00","labels":["architecture","opus-4.5","spike"],"dependencies":[{"issue_id":"ytsync-uff.1","depends_on_id":"ytsync-uff","type":"parent-child","created_at":"2026-01-10T16:27:05.573914-05:00","created_by":"daemon"}]}
{"id":"ytsync-uff.2","title":"Implement JSON File Storage Backend","description":"Implement the JSON file storage backend:\n\n## Files to Create\n- internal/storage/json_store.go\n\n## JSONStore Implementation\nImplement the Store interface using a single JSON file with in-memory caching.\n\n### Internal Data Structure (storeData)\n- Version (string, schema version)\n- UpdatedAt (time.Time)\n- Channels (map[string]*Channel)\n- Videos (map[string]*Video)\n- Transcripts (map[string]*Transcript)\n- SyncStates (map[string]*SyncState)\n- Indexes (lookup indexes for efficient queries)\n\n### Indexes to Maintain\n- YouTubeChannelID: map[youtube_id] -\u003e channel_id\n- YouTubeVideoID: map[youtube_id] -\u003e video_id\n- VideosByChannel: map[channel_id] -\u003e []video_id\n\n### Core Methods\n- NewJSONStore(path string) (*JSONStore, error)\n- load() error - Load JSON file into memory\n- save() error - Persist to disk using AtomicWriter\n- Close() error - Release file lock\n\n### Concurrency\n- sync.RWMutex for in-memory data protection\n- FileLock for multi-process safety\n- RLock for read operations, Lock for writes\n\n### Dependencies\n- Requires: ytsync-uff.3 (Data Models)\n- Requires: ytsync-uff.4 (Storage Interfaces)\n- Requires: ytsync-uff.5 (Atomic Operations)\n\n## Reference\nSee spike ytsync-uff.1 notes for JSON schema and implementation structure.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T16:27:05.970727-05:00","updated_at":"2026-01-10T18:01:37.194138-05:00","closed_at":"2026-01-10T18:01:37.194138-05:00","close_reason":"Closed","labels":["implementation"],"dependencies":[{"issue_id":"ytsync-uff.2","depends_on_id":"ytsync-uff","type":"parent-child","created_at":"2026-01-10T16:27:05.971252-05:00","created_by":"daemon"}]}
{"id":"ytsync-uff.3","title":"Define Data Models","description":"Define Go structs for all data entities:\n\n## Files to Create\n- internal/storage/models.go\n\n## Structs to Define\n\n### Channel\n- ID (string, internal UUID)\n- YouTubeID (string, YouTube channel ID UC...)\n- Name, Description, URL (strings)\n- CreatedAt, UpdatedAt (time.Time)\n\n### Video\n- ID (string, internal UUID)\n- YouTubeID (string, YouTube video ID)\n- ChannelID (string, FK to Channel.ID)\n- Title, Description (strings)\n- PublishedAt (time.Time)\n- Duration (int, seconds)\n- HasTranscript (bool)\n- CreatedAt, UpdatedAt (time.Time)\n\n### Transcript\n- VideoID (string, FK to Video.ID)\n- Language (string, e.g. en, auto)\n- Content (string, plain text)\n- Segments ([]Segment, optional timed segments)\n- Source (string, e.g. youtube, whisper)\n- CreatedAt, UpdatedAt (time.Time)\n\n### Segment\n- Start, End (float64, seconds)\n- Text (string)\n\n### SyncState\n- ChannelID (string)\n- LastSyncAt (time.Time)\n- LastVideoID (string, for pagination)\n- VideosProcessed, TotalVideos (int)\n- Status (string: idle, syncing, error)\n- LastError (string, optional)\n\n## JSON Tags\nAll fields must have appropriate json tags for serialization.\n\n## Reference\nSee spike ytsync-uff.1 notes for complete struct definitions.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T16:27:06.365866-05:00","updated_at":"2026-01-10T18:00:08.264458-05:00","closed_at":"2026-01-10T18:00:08.264458-05:00","close_reason":"Closed","labels":["implementation"],"dependencies":[{"issue_id":"ytsync-uff.3","depends_on_id":"ytsync-uff","type":"parent-child","created_at":"2026-01-10T16:27:06.366406-05:00","created_by":"daemon"}]}
{"id":"ytsync-uff.4","title":"Define Storage Interfaces","description":"Create Go interfaces for the storage abstraction layer:\n\n## Files to Create\n- internal/storage/storage.go\n\n## Interfaces to Define\n1. Store - Main composite interface embedding all sub-interfaces\n2. ChannelStore - CRUD operations for Channel entities\n3. VideoStore - CRUD operations for Video entities  \n4. TranscriptStore - CRUD operations for Transcript entities\n5. SyncStateStore - Operations for sync state tracking\n\n## Key Design Points\n- All methods accept context.Context as first parameter\n- Return pointers for entities (nil for not found)\n- Use sentinel errors: ErrNotFound, ErrAlreadyExists, ErrInvalidInput\n- Include StorageError wrapper type for detailed error context\n- Store interface must embed Close() error method\n\n## Reference\nSee spike ytsync-uff.1 notes for complete interface definitions.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T16:37:54.129214-05:00","updated_at":"2026-01-10T18:00:08.260556-05:00","closed_at":"2026-01-10T18:00:08.260556-05:00","close_reason":"Closed","labels":["implementation"],"dependencies":[{"issue_id":"ytsync-uff.4","depends_on_id":"ytsync-uff","type":"parent-child","created_at":"2026-01-10T16:37:54.129785-05:00","created_by":"daemon"}]}
{"id":"ytsync-uff.5","title":"Implement Atomic File Operations Utility","description":"Create utilities for atomic file write operations and file locking:\n\n## Files to Create\n- internal/storage/atomic.go\n- internal/storage/filelock.go\n\n## AtomicWriter\n- Write to temp file in same directory (.ytsync-*.tmp)\n- Sync to disk before rename\n- Atomic rename to target path on Commit()\n- Abort() method for cleanup on error\n- Implements io.Writer interface\n\n## FileLock\n- Advisory file locking using syscall.Flock\n- Lock() method with timeout parameter\n- Unlock() method with cleanup\n- Cross-platform considerations (darwin, linux)\n- Lock file path: \u003cdatafile\u003e.lock\n\n## Error Handling\n- ErrLockTimeout sentinel error\n- Proper cleanup on all error paths\n- Best-effort cleanup of temp files\n\n## Reference\nSee spike ytsync-uff.1 notes for implementation patterns.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T16:38:02.46098-05:00","updated_at":"2026-01-10T18:00:34.298889-05:00","closed_at":"2026-01-10T18:00:34.298889-05:00","close_reason":"Closed","labels":["implementation"],"dependencies":[{"issue_id":"ytsync-uff.5","depends_on_id":"ytsync-uff","type":"parent-child","created_at":"2026-01-10T16:38:02.465338-05:00","created_by":"daemon"}]}
{"id":"ytsync-uff.6","title":"Unit Tests for Storage Layer","description":"Create comprehensive unit tests for the storage layer:\n\n## Files to Create\n- internal/storage/storage_test.go\n- internal/storage/models_test.go\n- internal/storage/atomic_test.go\n- internal/storage/filelock_test.go\n\n## Test Coverage\n\n### Interface Tests (storage_test.go)\n- Test helper that works with any Store implementation\n- CRUD operations for each entity type\n- Error conditions (not found, already exists)\n- Concurrent read/write operations\n\n### Model Tests (models_test.go)\n- JSON serialization/deserialization roundtrip\n- Validation of required fields\n- Time handling across serialization\n\n### AtomicWriter Tests (atomic_test.go)\n- Successful write and commit\n- Abort cleans up temp file\n- Concurrent writes to different files\n- Error handling (permission denied, disk full simulation)\n\n### FileLock Tests (filelock_test.go)\n- Lock acquisition and release\n- Timeout behavior\n- Multiple processes (using separate goroutines)\n- Cleanup on unlock\n\n## Test Patterns\n- Use t.TempDir() for test directories\n- Table-driven tests where appropriate\n- Parallel tests where safe (t.Parallel())\n- Clean teardown in all cases\n\n## Dependencies\n- Requires: ytsync-uff.3, ytsync-uff.4, ytsync-uff.5","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T16:38:30.015732-05:00","updated_at":"2026-01-10T18:06:19.376117-05:00","closed_at":"2026-01-10T18:06:19.376117-05:00","close_reason":"Closed","labels":["implementation","testing"],"dependencies":[{"issue_id":"ytsync-uff.6","depends_on_id":"ytsync-uff","type":"parent-child","created_at":"2026-01-10T16:38:30.018877-05:00","created_by":"daemon"}]}
{"id":"ytsync-uff.7","title":"Integration Tests for Persistence","description":"Create integration tests for end-to-end persistence scenarios:\n\n## Files to Create\n- internal/storage/integration_test.go\n\n## Test Scenarios\n\n### Data Persistence Across Sessions\n- Create store, add data, close store\n- Reopen store, verify data persisted\n- Test version/schema handling\n\n### Crash Recovery\n- Simulate crash during write (kill before commit)\n- Verify previous valid state preserved\n- No partial/corrupt data\n\n### Concurrent Access\n- Multiple goroutines performing operations\n- Verify data consistency\n- No race conditions (run with -race flag)\n\n### Large Dataset Handling\n- Test with 1000+ videos\n- Performance benchmarks for common operations\n- Memory usage verification\n\n### Index Consistency\n- Add/remove entities\n- Verify indexes stay in sync\n- Query by YouTube ID after modifications\n\n### Error Recovery\n- Corrupted JSON file handling\n- Missing file initialization\n- Permission errors\n\n## Test Build Tag\nUse build tag for integration tests:\n//go:build integration\n\n## Run Command\ngo test -tags=integration -race ./internal/storage/...\n\n## Dependencies\n- Requires: ytsync-uff.2 (JSON Store implementation)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T16:38:38.908855-05:00","updated_at":"2026-01-10T18:07:08.088517-05:00","closed_at":"2026-01-10T18:07:08.088517-05:00","close_reason":"Closed","labels":["implementation","testing"],"dependencies":[{"issue_id":"ytsync-uff.7","depends_on_id":"ytsync-uff","type":"parent-child","created_at":"2026-01-10T16:38:38.913606-05:00","created_by":"daemon"}]}
{"id":"ytsync-zy1","title":"ytsync: GitHub Actions CI/CD","status":"open","priority":1,"issue_type":"epic","created_at":"2026-01-10T19:54:48.318331-05:00","updated_at":"2026-01-10T19:54:48.318331-05:00"}
{"id":"ytsync-zy1.1","title":"Setup GitHub Actions test workflow","description":"Create .github/workflows/test.yml that runs on every push and PR. Should run: go test ./... with coverage reporting. Test on multiple Go versions (1.25, latest).","status":"in_progress","priority":1,"issue_type":"task","created_at":"2026-01-10T19:54:52.033914-05:00","updated_at":"2026-01-10T20:12:41.34641-05:00","dependencies":[{"issue_id":"ytsync-zy1.1","depends_on_id":"ytsync-zy1","type":"parent-child","created_at":"2026-01-10T19:54:52.037334-05:00","created_by":"daemon"}]}
{"id":"ytsync-zy1.2","title":"Setup GitHub Actions lint workflow","description":"Create .github/workflows/lint.yml that runs golangci-lint on every push and PR. Should check for: go fmt, go vet, unused code, etc. Fail the check if issues found.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-10T19:54:55.305293-05:00","updated_at":"2026-01-10T19:54:55.305293-05:00","dependencies":[{"issue_id":"ytsync-zy1.2","depends_on_id":"ytsync-zy1","type":"parent-child","created_at":"2026-01-10T19:54:55.309538-05:00","created_by":"daemon"}]}
{"id":"ytsync-zy1.3","title":"Setup GitHub Actions build release workflow","description":"Create .github/workflows/release.yml that triggers on git tags (v*.*.*). Should build binaries for: linux/amd64, linux/arm64, darwin/amd64, darwin/arm64, windows/amd64. Create GitHub release with binaries and checksums.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-10T19:54:58.677973-05:00","updated_at":"2026-01-10T19:54:58.677973-05:00","dependencies":[{"issue_id":"ytsync-zy1.3","depends_on_id":"ytsync-zy1","type":"parent-child","created_at":"2026-01-10T19:54:58.680629-05:00","created_by":"daemon"}]}
{"id":"ytsync-zy1.4","title":"Setup GitHub Actions build CLI workflow","description":"Create .github/workflows/build.yml that builds the CLI on every commit to verify it compiles. Should build for current platform and upload as artifact. Helps catch build errors early.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-10T19:55:04.707804-05:00","updated_at":"2026-01-10T19:55:04.707804-05:00","dependencies":[{"issue_id":"ytsync-zy1.4","depends_on_id":"ytsync-zy1","type":"parent-child","created_at":"2026-01-10T19:55:04.711335-05:00","created_by":"daemon"}]}
